{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tweet Classifier\n",
    "\n",
    "This tweet classifier uses a public tweet training / testing dataset created by Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from __future__ import division, print_function\n",
    "\n",
    "\n",
    "\n",
    "#modeling includes\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training.1600000.processed.noemoticon.csv', header=None)\n",
    "df.columns = ['polarity', 'tweet_id', 'date', 'query', 'user', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Quick EDA\n",
    "\n",
    "We're going to take a quick look at our training dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of this dataset noted that positive tweets are labled 4 and negative tweets are labeled 0.  So, we have 800,000 positive tweets, and 800,000 negative tweets.   Lets look at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.polarity == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822272</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ersle</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822273</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>becca210</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822283</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Wingman29</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822287</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>katarinka</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822293</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_EmilyYoung</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity    tweet_id                          date     query  \\\n",
       "800000         4  1467822272  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "800001         4  1467822273  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "800002         4  1467822283  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "800003         4  1467822287  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "800004         4  1467822293  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \n",
       "800000        ersle       I LOVE @Health4UandPets u guys r the best!!   \n",
       "800001     becca210  im meeting up with one of my besties tonight! ...  \n",
       "800002    Wingman29  @DaRealSunisaKim Thanks for the Twitter add, S...  \n",
       "800003    katarinka  Being sick can be really cheap when it hurts t...  \n",
       "800004  _EmilyYoung    @LovesBrooklyn2 he has that effect on everyone   "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.polarity == 4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    df = pd.read_csv('data/training.1600000.processed.noemoticon.csv', \n",
    "                     names=['polarity', 'tweet_id', 'date', 'query', 'user', 'text'],\n",
    "                     header=None,\n",
    "                     encoding='ISO-8859-1')\n",
    "    df.drop(['tweet_id','date','query','user'], axis=1, inplace=True)\n",
    "    df.polarity.replace(4,1, inplace=True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_testing_data():\n",
    "    df = pd.read_csv('data/testdata.manual.2009.06.14.csv', \n",
    "                     names=['polarity', 'tweet_id', 'date', 'query', 'user', 'text'],\n",
    "                     header=None,\n",
    "                     encoding='ISO-8859-1')\n",
    "    df.drop(['tweet_id','date','query','user'], axis=1, inplace=True)\n",
    "    df.polarity.replace(4,1, inplace=True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_tweets = create_training_data()\n",
    "y_train = training_tweets.pop('polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_tweets = create_testing_data()\n",
    "neutral_tests = testing_tweets[testing_tweets.polarity == 2]\n",
    "testing_tweest = testing_tweets[testing_tweets.polarity.isin([0,1])] \n",
    "y_test = testing_tweets.pop('polarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_tweets(x):\n",
    "    x = x.lower()  #lowercase everything\n",
    "    x = re.sub('@[a-z_-]+',\"\",x) #remove handles\n",
    "    x = re.sub('[0-9]+',\"\",x)  #remove numbers\n",
    "    x = re.sub('(https?):\\/\\/(www\\.)?[a-z0-9\\.:].*?(?=\\s)', \"\",x) #remove urls\n",
    "    x = re.sub('&[a-z]+','',x)  #remove html punctuations &amp, etc...\n",
    "    return x\n",
    "\n",
    "training_tweets.text = training_tweets.text.map(clean_tweets)\n",
    "testing_tweets.text = testing_tweets.text.map(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopset = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(use_idf=True, encoding='ISO-8859-1',\n",
    "                             lowercase=True, strip_accents='ascii', stop_words=stopset,\n",
    "                            min_df = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(training_tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(testing_tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will train a naive_bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-49bcc1a54cb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/mike/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m     return _average_binary_score(\n\u001b[0;32m    252\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/anaconda/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fuck this economy. I hate aig and their non lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jquery is my new best friend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loves twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Check this video out -- President Obama at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>House Correspondents dinner was last night who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Watchin Espn..Jus seen this new Nike Commerica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dear nike, stop with the flywire. that shit is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>#lebron best athlete of our generation, if not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I was talking to this guy last night and he wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i love lebron. http://bit.ly/PdHur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@ludajuice Lebron is a Beast, but I'm still ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@Pmillzz lebron IS THE BOSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@sketchbug Lebron is a hometown hero to me, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lebron and zydrunas are such an awesome duo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@wordwhizkid Lebron is a beast... nobody in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>downloading apps for my iphone! So much fun :-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>good news, just had a call from the Visa offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>http://twurl.nl/epkr4b - awesome come back fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>In montreal for a long weekend of R&amp;amp;R. Muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Booz Allen Hamilton has a bad ass homegrown so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[#MLUC09] Customer Innovation Award Winner: Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@SoChi2 I current use the Nikon D90 and love i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Man I kinda dislike Apple right now. Case in p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>@cwong08 I have a Kindle2 (&amp;amp; Sony PRS-500)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>The #Kindle2 seems the best eReader, but will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>I have a google addiction. Thank you for point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>@ruby_gem My primary debit card is Visa Electron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Off to the bank to get my new visa platinum card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>dearest @google, you rich bastards! the VISA c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>has a date with bobby flay and gut fieri from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Excited about seeing Bobby Flay and Guy Fieri ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Gonna go see Bobby Flay 2moro at Shoreline. Ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>can't wait for the great american food and mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>My dad was in NY for a day, we ate at MESA gri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Fighting with LaTex. Again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>@Iheartseverus we love you too and don't want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>7 hours. 7 hours of inkscape crashing, normall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>How to Track Iran with Social Media: http://bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Shit's hitting the fan in Iran...craziness ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>Monday already. Iran may implode. Kitchen is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Twitter Stock buzz: $AAPL $ES_F $SPY $SPX $PAL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>getting ready to test out some burger receipes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>@johncmayer is Bobby Flay joining you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>i lam so in love with Bobby Flay... he is my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>I just created my first LaTeX file from scratc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>using Linux and loving it - so much nicer than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>After using LaTeX a lot, any other typeset mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    @stellargirl I loooooooovvvvvveee my Kindle2. ...\n",
       "1    Reading my kindle2...  Love it... Lee childs i...\n",
       "2    Ok, first assesment of the #kindle2 ...it fuck...\n",
       "3    @kenburbary You'll love your Kindle2. I've had...\n",
       "4    @mikefish  Fair enough. But i have the Kindle2...\n",
       "5    @richardebaker no. it is too big. I'm quite ha...\n",
       "6    Fuck this economy. I hate aig and their non lo...\n",
       "7                        Jquery is my new best friend.\n",
       "8                                        Loves twitter\n",
       "9    how can you not love Obama? he makes jokes abo...\n",
       "10   Check this video out -- President Obama at the...\n",
       "11   @Karoli I firmly believe that Obama/Pelosi hav...\n",
       "12   House Correspondents dinner was last night who...\n",
       "13   Watchin Espn..Jus seen this new Nike Commerica...\n",
       "14   dear nike, stop with the flywire. that shit is...\n",
       "15   #lebron best athlete of our generation, if not...\n",
       "16   I was talking to this guy last night and he wa...\n",
       "17                  i love lebron. http://bit.ly/PdHur\n",
       "18   @ludajuice Lebron is a Beast, but I'm still ch...\n",
       "19                         @Pmillzz lebron IS THE BOSS\n",
       "20   @sketchbug Lebron is a hometown hero to me, lo...\n",
       "21         lebron and zydrunas are such an awesome duo\n",
       "22   @wordwhizkid Lebron is a beast... nobody in th...\n",
       "23   downloading apps for my iphone! So much fun :-...\n",
       "24   good news, just had a call from the Visa offic...\n",
       "25   http://twurl.nl/epkr4b - awesome come back fro...\n",
       "26   In montreal for a long weekend of R&amp;R. Muc...\n",
       "27   Booz Allen Hamilton has a bad ass homegrown so...\n",
       "28   [#MLUC09] Customer Innovation Award Winner: Bo...\n",
       "29   @SoChi2 I current use the Nikon D90 and love i...\n",
       "..                                                 ...\n",
       "468  Man I kinda dislike Apple right now. Case in p...\n",
       "469  @cwong08 I have a Kindle2 (&amp; Sony PRS-500)...\n",
       "470  The #Kindle2 seems the best eReader, but will ...\n",
       "471  I have a google addiction. Thank you for point...\n",
       "472  @ruby_gem My primary debit card is Visa Electron.\n",
       "473   Off to the bank to get my new visa platinum card\n",
       "474  dearest @google, you rich bastards! the VISA c...\n",
       "475  has a date with bobby flay and gut fieri from ...\n",
       "476  Excited about seeing Bobby Flay and Guy Fieri ...\n",
       "477  Gonna go see Bobby Flay 2moro at Shoreline. Ea...\n",
       "478  can't wait for the great american food and mus...\n",
       "479  My dad was in NY for a day, we ate at MESA gri...\n",
       "480                      Fighting with LaTex. Again...\n",
       "481  @Iheartseverus we love you too and don't want ...\n",
       "482  7 hours. 7 hours of inkscape crashing, normall...\n",
       "483  How to Track Iran with Social Media: http://bi...\n",
       "484  Shit's hitting the fan in Iran...craziness ind...\n",
       "485  Monday already. Iran may implode. Kitchen is a...\n",
       "486  Twitter Stock buzz: $AAPL $ES_F $SPY $SPX $PAL...\n",
       "487  getting ready to test out some burger receipes...\n",
       "488             @johncmayer is Bobby Flay joining you?\n",
       "489  i lam so in love with Bobby Flay... he is my f...\n",
       "490  I just created my first LaTeX file from scratc...\n",
       "491  using Linux and loving it - so much nicer than...\n",
       "492  After using LaTeX a lot, any other typeset mat...\n",
       "493  Ask Programming: LaTeX or InDesign?: submitted...\n",
       "494  On that note, I hate Word. I hate Pages. I hat...\n",
       "495  Ahhh... back in a *real* text editing environm...\n",
       "496  Trouble in Iran, I see. Hmm. Iran. Iran so far...\n",
       "497  Reading the tweets coming out of Iran... The w...\n",
       "\n",
       "[498 rows x 1 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
